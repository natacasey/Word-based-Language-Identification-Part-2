{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the packages\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from textblob import TextBlob\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import langdetect\n",
    "from langdetect import detect\n",
    "import detectlanguage\n",
    "from google_trans_new import google_translator  \n",
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr_0112905</td>\n",
       "      <td>product_fr_0620743</td>\n",
       "      <td>reviewer_fr_0310864</td>\n",
       "      <td>1</td>\n",
       "      <td>Colis bien reçus avec le boîtier du jeu ouvert...</td>\n",
       "      <td>Commandé ailleurs si vous voulez des colis com...</td>\n",
       "      <td>fr</td>\n",
       "      <td>video_games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr_0345365</td>\n",
       "      <td>product_fr_0942745</td>\n",
       "      <td>reviewer_fr_0244013</td>\n",
       "      <td>1</td>\n",
       "      <td>Suite à une vérification, je vous informe que ...</td>\n",
       "      <td>COMMANDE NON RECUE</td>\n",
       "      <td>fr</td>\n",
       "      <td>office_product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr_0474170</td>\n",
       "      <td>product_fr_0183830</td>\n",
       "      <td>reviewer_fr_0816879</td>\n",
       "      <td>1</td>\n",
       "      <td>C'est un produit de piètre qualité sur quatre,...</td>\n",
       "      <td>Plastique sans aucune résistance !</td>\n",
       "      <td>fr</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr_0084156</td>\n",
       "      <td>product_fr_0195761</td>\n",
       "      <td>reviewer_fr_0933238</td>\n",
       "      <td>1</td>\n",
       "      <td>N'ont pas résistés. Piètre qualité</td>\n",
       "      <td>séparateur d'orteils</td>\n",
       "      <td>fr</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr_0893613</td>\n",
       "      <td>product_fr_0077995</td>\n",
       "      <td>reviewer_fr_0492122</td>\n",
       "      <td>1</td>\n",
       "      <td>Filament de qualité mais pas bien embobiné, ré...</td>\n",
       "      <td>ça coince, ça coince... que des problemes</td>\n",
       "      <td>fr</td>\n",
       "      <td>industrial_supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>en_0447642</td>\n",
       "      <td>product_en_0068982</td>\n",
       "      <td>reviewer_en_0061521</td>\n",
       "      <td>5</td>\n",
       "      <td>This ribbon is so adorable! Goes perfect with ...</td>\n",
       "      <td>So Cute!</td>\n",
       "      <td>en</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>en_0950370</td>\n",
       "      <td>product_en_0563046</td>\n",
       "      <td>reviewer_en_0871798</td>\n",
       "      <td>5</td>\n",
       "      <td>I am in love with this kettle.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>en</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>en_0203466</td>\n",
       "      <td>product_en_0848682</td>\n",
       "      <td>reviewer_en_0474236</td>\n",
       "      <td>5</td>\n",
       "      <td>My Doberman Loves Having His Nails Trimmed and...</td>\n",
       "      <td>My Doberman Loves Them</td>\n",
       "      <td>en</td>\n",
       "      <td>pet_products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>en_0010627</td>\n",
       "      <td>product_en_0536493</td>\n",
       "      <td>reviewer_en_0546192</td>\n",
       "      <td>5</td>\n",
       "      <td>I love my Fire.. I do everything on it, read, ...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>en</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>en_0290511</td>\n",
       "      <td>product_en_0964853</td>\n",
       "      <td>reviewer_en_0850986</td>\n",
       "      <td>5</td>\n",
       "      <td>A wish I would've ordered one size smaller (I ...</td>\n",
       "      <td>SUPER CUTE!</td>\n",
       "      <td>en</td>\n",
       "      <td>apparel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_id          product_id          reviewer_id  stars  \\\n",
       "0      fr_0112905  product_fr_0620743  reviewer_fr_0310864      1   \n",
       "1      fr_0345365  product_fr_0942745  reviewer_fr_0244013      1   \n",
       "2      fr_0474170  product_fr_0183830  reviewer_fr_0816879      1   \n",
       "3      fr_0084156  product_fr_0195761  reviewer_fr_0933238      1   \n",
       "4      fr_0893613  product_fr_0077995  reviewer_fr_0492122      1   \n",
       "...           ...                 ...                  ...    ...   \n",
       "19995  en_0447642  product_en_0068982  reviewer_en_0061521      5   \n",
       "19996  en_0950370  product_en_0563046  reviewer_en_0871798      5   \n",
       "19997  en_0203466  product_en_0848682  reviewer_en_0474236      5   \n",
       "19998  en_0010627  product_en_0536493  reviewer_en_0546192      5   \n",
       "19999  en_0290511  product_en_0964853  reviewer_en_0850986      5   \n",
       "\n",
       "                                             review_body  \\\n",
       "0      Colis bien reçus avec le boîtier du jeu ouvert...   \n",
       "1      Suite à une vérification, je vous informe que ...   \n",
       "2      C'est un produit de piètre qualité sur quatre,...   \n",
       "3                     N'ont pas résistés. Piètre qualité   \n",
       "4      Filament de qualité mais pas bien embobiné, ré...   \n",
       "...                                                  ...   \n",
       "19995  This ribbon is so adorable! Goes perfect with ...   \n",
       "19996                     I am in love with this kettle.   \n",
       "19997  My Doberman Loves Having His Nails Trimmed and...   \n",
       "19998  I love my Fire.. I do everything on it, read, ...   \n",
       "19999  A wish I would've ordered one size smaller (I ...   \n",
       "\n",
       "                                            review_title language  \\\n",
       "0      Commandé ailleurs si vous voulez des colis com...       fr   \n",
       "1                                     COMMANDE NON RECUE       fr   \n",
       "2                     Plastique sans aucune résistance !       fr   \n",
       "3                                   séparateur d'orteils       fr   \n",
       "4              ça coince, ça coince... que des problemes       fr   \n",
       "...                                                  ...      ...   \n",
       "19995                                           So Cute!       en   \n",
       "19996                                            Perfect       en   \n",
       "19997                             My Doberman Loves Them       en   \n",
       "19998                                         Five Stars       en   \n",
       "19999                                        SUPER CUTE!       en   \n",
       "\n",
       "          product_category  \n",
       "0              video_games  \n",
       "1           office_product  \n",
       "2               automotive  \n",
       "3                   sports  \n",
       "4      industrial_supplies  \n",
       "...                    ...  \n",
       "19995                 home  \n",
       "19996              kitchen  \n",
       "19997         pet_products  \n",
       "19998                other  \n",
       "19999              apparel  \n",
       "\n",
       "[20000 rows x 8 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading development datasets and concatenating thhem\n",
    "dev_de = pd.read_json(\"dataset_de_dev.json\", lines=True)\n",
    "dev_es = pd.read_json(\"dataset_es_dev.json\", lines=True)\n",
    "dev_en = pd.read_json(\"dataset_en_dev.json\", lines=True)\n",
    "dev_fr = pd.read_json(\"dataset_fr_dev.json\", lines=True)\n",
    "dev= pd.concat([dev_fr, dev_es, dev_de, dev_en], axis=0)\n",
    "dev.reset_index(drop=True, inplace=True)\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data pre-processed with unique linguistic characteristics\n",
    "train=pd.read_excel('train_df_clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data with \n",
    "train_nostop=pd.read_excel('no_stopw.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the data set\n",
    "train_nostop= train_nostop[train_nostop['review_body'].notnull()]\n",
    "train_nostop.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data with all stop words\n",
    "train_sw=pd.read_excel('train_sw.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traiing set with stemmed data\n",
    "train_lemma=pd.read_excel('train_lemma.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "test=pd.read_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Europarl long\n",
    "formal_large=pd.read_excel('formal_large.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_short_nostop=pd.read_excel('formal_nostop.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>want imagine wearable</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Berkeley Bionics call</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   text lang\n",
       "0           0  want imagine wearable   en\n",
       "1           1  Berkeley Bionics call   en"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional=pd.read_excel('functional_words.xlsx')\n",
    "functional.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "functional=functional[functional['text'].str.split().str.len().ge(2)]\n",
    "functional= functional[functional['text'].notnull()]\n",
    "\n",
    "functional.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106182, 3)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fr    28186\n",
       "en    28083\n",
       "de    25346\n",
       "es    24567\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I want you now to imagine a wearable robot tha...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We at Berkeley Bionics call these robots exosk...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text lang\n",
       "0           0  I want you now to imagine a wearable robot tha...   en\n",
       "1           1  We at Berkeley Bionics call these robots exosk...   en"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_talk_full=pd.read_excel('tedtalk_full_large.xlsx')\n",
    "ted_talk_full=ted_talk_full[ted_talk_full['text'].str.split().str.len().ge(4)]\n",
    "ted_talk_full= ted_talk_full[ted_talk_full['text'].notnull()]\n",
    "ted_talk_full.reset_index(drop=True, inplace=True)\n",
    "ted_talk_full.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124157, 3)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_talk_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    32156\n",
       "fr    31966\n",
       "es    30680\n",
       "de    29355\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_talk_full['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the performance of MNB for monolingual pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set with monolingual pre-processing\n",
    "train_mono=pd.read_excel('train_mono.xlsx')\n",
    "train_mono= train_mono[train_mono['review_body'].notnull()]\n",
    "train_mono.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.84284999999999998810\n",
      "[[4818  103   72    7]\n",
      " [ 432 4464   69   35]\n",
      " [1423   27 3269  281]\n",
      " [ 320   27  347 4306]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.84745000000000003659\n",
      "[[4814  116   65    5]\n",
      " [ 425 4481   63   31]\n",
      " [1334   22 3336  308]\n",
      " [ 290   27  365 4318]]\n",
      "0.4894280498935199\n",
      "0.4819906843804584\n",
      "------------------------------\n",
      "accuracy validation set:  0.48127773705872400889\n",
      "[[19995  4564  3323  1473]\n",
      " [12760 16979   960  1457]\n",
      " [19231   391  8347  2711]\n",
      " [12298   652  4583 14433]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.51847770808611626236\n",
      "[[23870   799   514   163]\n",
      " [ 8570 17328  1381   804]\n",
      " [21519   341  2346   361]\n",
      " [15500   596   581 11509]]\n"
     ]
    }
   ],
   "source": [
    "#training and testing MNB over the data pre-processed as monolingual data\n",
    "train_X = train_mono['review_body']   \n",
    "train_y = train_mono['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None, max_features=10000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_tf, train_y)\n",
    "y_pred = lr.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=lr.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))\n",
    "\n",
    "import pickle\n",
    "filename_lr = 'model_lr_10k.sav'\n",
    "pickle.dump(lr, open(filename_lr, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model_train_lr = pickle.load(open(filename_lr, 'rb'))\n",
    "\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train_lr.score(x_formal, formal_large.lang)\n",
    "print(result)\n",
    "\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train_lr.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)\n",
    "\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=lr.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))\n",
    "\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=lr.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "import pickle\n",
    "filename_10k = 'model_train_mono_10k.sav'\n",
    "pickle.dump(naive_bayes_classifier, open(filename_10k, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model_mono_10k = pickle.load(open(filename_10k, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of MNB with 10,000 features and trained over the data pre-processed accounting for linguistic nuances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec_up_more = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=1000000, ngram_range=(1, 3))\n",
    "#pipeline for 1,000,000 features\n",
    "clf = MultinomialNB()\n",
    "bayes_pipeline_up_more = Pipeline([\n",
    "    ('vectorizer', tvec_up_more),\n",
    "    ('classifier', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              de          en          es       fr\n",
      "precision: [0.99885109 0.99992499 1.         0.99987493]\n",
      "recall:    [0.99989999 0.99987499 0.99942494 0.99944994]\n",
      "f1 score:  [0.99937527 0.99989999 0.99971239 0.99966239]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99850165 0.99960007 0.99997498 0.99994996]\n",
      "recall:    [0.99969997 0.99987499 0.99917492 0.99927493]\n",
      "f1 score:  [0.99910045 0.99973751 0.99957479 0.99961233]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99895087 0.99984999 0.99997498 0.99989996]\n",
      "recall:    [0.99987499 0.99989999 0.99932493 0.99957496]\n",
      "f1 score:  [0.99941271 0.99987499 0.99964985 0.99973743]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.9992005  0.99989999 0.99997499 0.99989996]\n",
      "recall:    [0.99992499 0.99987499 0.99949995 0.99967496]\n",
      "f1 score:  [0.99956261 0.99988749 0.99973741 0.99978745]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99877604 0.99967504 0.99994996 0.99994997]\n",
      "recall:    [0.99972497 0.99989999 0.99932493 0.99939992]\n",
      "f1 score:  [0.99925028 0.9997875  0.99963735 0.99967487]\n",
      "--------------------------------------------------------\n",
      "accuracy: 99.963% (+/- 0.01%)\n",
      "precision: 99.963% (+/- 0.01%)\n",
      "recall: 99.963% (+/- 0.01%)\n",
      "f1 score: 99.963% (+/- 0.01%)\n"
     ]
    }
   ],
   "source": [
    "#Stratified k-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "X=train.new\n",
    "Y=train.language\n",
    "for train, test in kfold.split(X, Y):\n",
    "    lr_fit = bayes_pipeline_up_more.fit(X[train], Y[train])\n",
    "    prediction = lr_fit.predict(X[test])\n",
    "    scores = lr_fit.score(X[test],Y[test])\n",
    "    #model_result=lr_fit.predict(testing)\n",
    "    accuracy.append(scores * 100)\n",
    "    precision.append(precision_score(Y[test], prediction, average='macro')*100)\n",
    "    print('              de          en          es       fr')\n",
    "    print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "    recall.append(recall_score(Y[test], prediction, average='macro')*100)\n",
    "    print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "    f1.append(f1_score(Y[test], prediction, average='macro')*100)\n",
    "    print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "    print('-'*56)\n",
    "\n",
    "print(\"accuracy: %.3f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "print(\"precision: %.3f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "print(\"recall: %.3f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "print(\"f1 score: %.3f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.99970000000000003304\n",
      "[[5000    0    0    0]\n",
      " [   1 4999    0    0]\n",
      " [   1    0 4999    0]\n",
      " [   4    0    0 4996]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.99980000000000002203\n",
      "[[4998    2    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   1    0 4999    0]\n",
      " [   1    0    0 4999]]\n"
     ]
    }
   ],
   "source": [
    "#training and testing the model on test and dev sets\n",
    "train_X = train['new']   \n",
    "train_y = train['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=10000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=naive_bayes_classifier.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "import pickle\n",
    "filename_10k = 'model_train_tfidf_10k.sav'\n",
    "pickle.dump(naive_bayes_classifier, open(filename_10k, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9967168644153737\n",
      "0.8060128089768698\n",
      "------------------------------\n",
      "accuracy validation set:  0.97630419549441438409\n",
      "[[29222   103    10    20]\n",
      " [   86 32028    10    32]\n",
      " [ 1900   106 28587    87]\n",
      " [  480    67    41 31378]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.92291537172025395197\n",
      "[[25067   177    34    68]\n",
      " [ 1167 26546   112   258]\n",
      " [ 4194   104 20183    86]\n",
      " [ 1762   136    87 26201]]\n"
     ]
    }
   ],
   "source": [
    "#performance on long and short EuroParl, performance on long and short TED Talks sample\n",
    "import pickle\n",
    "filename_10k_new = 'model_train_tfidf_10k_new.sav'\n",
    "pickle.dump(naive_bayes_classifier, open(filename_10k_new, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model_train_10k_new = pickle.load(open(filename_10k_new, 'rb'))\n",
    "\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train_10k_new.score(x_formal, formal_large.lang)\n",
    "print(result)\n",
    "\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train_10k_new.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)\n",
    "\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=naive_bayes_classifier.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))\n",
    "\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=naive_bayes_classifier.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the baseline langid.py\n",
    "import langid\n",
    "from sklearn import metrics\n",
    "test_X = test['review_body']\n",
    "langid.set_languages(['de','fr','es','en'])\n",
    "langs=test['review_body'].apply(lambda x: langid.classify(x))\n",
    "first_tuple_elements = []\n",
    "for lang in langs:\n",
    "    first_tuple_elements.append(lang[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = metrics.accuracy_score(test.language,first_tuple_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy for the test set\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#langid.py performance on long Europarl \n",
    "import langid\n",
    "from sklearn import metrics\n",
    "#test_X = test['review_body']\n",
    "langid.set_languages(['de','fr','es','en'])\n",
    "langs=formal_large['txt'].apply(lambda x: langid.classify(x))\n",
    "first_tuple_elements = []\n",
    "for lang in langs:\n",
    "    first_tuple_elements.append(lang[0])\n",
    "score3=metrics.accuracy_score(formal_large.lang,first_tuple_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.99816195112057604089\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long Europarl\n",
    "print(\"accuracy validation set:  %0.20f\" % score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing for short Europarl\n",
    "import langid\n",
    "from sklearn import metrics\n",
    "langid.set_languages(['de','fr','es','en'])\n",
    "langs=formal_short_nostop['txt'].apply(lambda x: langid.classify(x))\n",
    "first_tuple_elements = []\n",
    "for lang in langs:\n",
    "    first_tuple_elements.append(lang[0])\n",
    "score4=metrics.accuracy_score(formal_short_nostop.lang,first_tuple_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.93252792039379661659\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short Europarl\n",
    "print(\"accuracy validation set:  %0.20f\" % score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing langid.py on long TED Talks\n",
    "import langid\n",
    "from sklearn import metrics\n",
    "langid.set_languages(['de','fr','es','en'])\n",
    "langs=ted_talk_full['text'].apply(lambda x: langid.classify(x))\n",
    "first_tuple_elements = []\n",
    "for lang in langs:\n",
    "    first_tuple_elements.append(lang[0])\n",
    "score5=metrics.accuracy_score(ted_talk_full.lang,first_tuple_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.99015762300957654851\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long TED Talks\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing on short TED Talks sample\n",
    "import langid\n",
    "from sklearn import metrics\n",
    "langid.set_languages(['de','fr','es','en'])\n",
    "langs=functional['text'].apply(lambda x: langid.classify(x))\n",
    "first_tuple_elements = []\n",
    "for lang in langs:\n",
    "    first_tuple_elements.append(lang[0])\n",
    "score6=metrics.accuracy_score(functional.lang,first_tuple_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.94658228324951498855\n"
     ]
    }
   ],
   "source": [
    "#accuracy for the short TED Talks sample\n",
    "print(\"accuracy validation set:  %0.20f\" % score6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNB with 100,000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec_up_more = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=100000, ngram_range=(1, 3))\n",
    "#pipeline for 100,000 features\n",
    "clf = MultinomialNB()\n",
    "bayes_pipeline_up_more = Pipeline([\n",
    "    ('vectorizer', tvec_up_more),\n",
    "    ('classifier', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              de          en          es       fr\n",
      "precision: [0.99987499 0.99995    1.         0.99994999]\n",
      "recall:    [0.99992499 0.999975   0.99992499 0.99994999]\n",
      "f1 score:  [0.99989999 0.9999625  0.99996249 0.99994999]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99977497 0.99957513 0.99994999 0.99997499]\n",
      "recall:    [0.99972497 0.999975   0.99984998 0.99972497]\n",
      "f1 score:  [0.99974997 0.99977502 0.99989998 0.99984997]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99972502 0.99985    1.         0.99997499]\n",
      "recall:    [0.99989999 0.99994999 0.99982498 0.99987499]\n",
      "f1 score:  [0.9998125  0.99989999 0.99991248 0.99992499]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99987499 0.99992499 0.999975   0.99994999]\n",
      "recall:    [0.99992499 0.99994999 0.99994999 0.99989999]\n",
      "f1 score:  [0.99989999 0.99993749 0.9999625  0.99992499]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99977499 0.99977502 1.         1.        ]\n",
      "recall:    [0.99984998 0.999975   0.99992499 0.99979997]\n",
      "f1 score:  [0.99981249 0.999875   0.99996249 0.99989998]\n",
      "--------------------------------------------------------\n",
      "accuracy: 99.989% (+/- 0.00%)\n",
      "precision: 99.989% (+/- 0.00%)\n",
      "recall: 99.989% (+/- 0.00%)\n",
      "f1 score: 99.989% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "#stratified cross validation for 100,000\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "X=train.new\n",
    "Y=train.language\n",
    "for train, test in kfold.split(X, Y):\n",
    "    lr_fit = bayes_pipeline_up_more.fit(X[train], Y[train])\n",
    "    prediction = lr_fit.predict(X[test])\n",
    "    scores = lr_fit.score(X[test],Y[test])\n",
    "    #model_result=lr_fit.predict(testing)\n",
    "    accuracy.append(scores * 100)\n",
    "    precision.append(precision_score(Y[test], prediction, average='macro')*100)\n",
    "    print('              de          en          es       fr')\n",
    "    print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "    recall.append(recall_score(Y[test], prediction, average='macro')*100)\n",
    "    print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "    f1.append(f1_score(Y[test], prediction, average='macro')*100)\n",
    "    print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "    print('-'*56)\n",
    "\n",
    "print(\"accuracy: %.3f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "print(\"precision: %.3f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "print(\"recall: %.3f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "print(\"f1 score: %.3f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.99995000000000000551\n",
      "[[5000    0    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   1    0    0 4999]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.99995000000000000551\n",
      "[[4999    1    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   0    0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "#training and testing the model for 100,000\n",
    "train_X = train['new']   \n",
    "train_y = train['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=100000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=naive_bayes_classifier.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving into a pickle\n",
    "import pickle\n",
    "filename_100k = 'model_train_tfidf_100k.sav'\n",
    "pickle.dump(naive_bayes_classifier, open(filename_100k, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model_train_100k = pickle.load(open(filename_100k, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9991887232532197\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long Europarl\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train_100k.score(x_formal, formal_large.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333218652410946\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short Europarl\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train_100k.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.99050395869745566646\n",
      "[[29244    90     9    12]\n",
      " [   30 32087     5    34]\n",
      " [  581   121 29925    53]\n",
      " [  143    75    26 31722]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for TED Talks long texts\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=naive_bayes_classifier.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.97508052212239360035\n",
      "[[25027   214    34    71]\n",
      " [  274 27596    63   150]\n",
      " [ 1016   131 23323    97]\n",
      " [  416   152    28 27590]]\n"
     ]
    }
   ],
   "source": [
    "#accuracies for short TED Talks\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=naive_bayes_classifier.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing MNB with 1,000,000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              de          en          es       fr\n",
      "precision: [0.99992499 0.99995    1.         0.999975  ]\n",
      "recall:    [0.99994999 0.999975   0.999975   0.99994999]\n",
      "f1 score:  [0.99993749 0.9999625  0.9999875  0.9999625 ]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99987497 0.99967506 1.         0.999975  ]\n",
      "recall:    [0.99972497 0.999975   0.99992499 0.99989999]\n",
      "f1 score:  [0.99979996 0.99982501 0.99996249 0.99993749]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99994999 0.99985    1.         0.99994999]\n",
      "recall:    [0.99989999 0.999975   0.99992499 0.99994999]\n",
      "f1 score:  [0.99992499 0.9999125  0.99996249 0.99994999]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.999975 0.999975 0.999975 0.999975]\n",
      "recall:    [0.999975   0.99994999 1.         0.999975  ]\n",
      "f1 score:  [0.999975  0.9999625 0.9999875 0.999975 ]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99989999 0.99985    1.         1.        ]\n",
      "recall:    [0.99987499 0.999975   0.999975   0.99992499]\n",
      "f1 score:  [0.99988749 0.9999125  0.9999875  0.99996249]\n",
      "--------------------------------------------------------\n",
      "accuracy: 99.994% (+/- 0.00%)\n",
      "precision: 99.994% (+/- 0.00%)\n",
      "recall: 99.994% (+/- 0.00%)\n",
      "f1 score: 99.994% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "#stratified k-fold validation  \n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "X=train.new\n",
    "Y=train.language\n",
    "for train, test in kfold.split(X, Y):\n",
    "    lr_fit = bayes_pipeline_up_more.fit(X[train], Y[train])\n",
    "    prediction = lr_fit.predict(X[test])\n",
    "    scores = lr_fit.score(X[test],Y[test])\n",
    "    #model_result=lr_fit.predict(testing)\n",
    "    accuracy.append(scores * 100)\n",
    "    precision.append(precision_score(Y[test], prediction, average='macro')*100)\n",
    "    print('              de          en          es       fr')\n",
    "    print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "    recall.append(recall_score(Y[test], prediction, average='macro')*100)\n",
    "    print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "    f1.append(f1_score(Y[test], prediction, average='macro')*100)\n",
    "    print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "    print('-'*56)\n",
    "\n",
    "print(\"accuracy: %.3f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "print(\"precision: %.3f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "print(\"recall: %.3f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "print(\"f1 score: %.3f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.99995000000000000551\n",
      "[[5000    0    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   1    0    0 4999]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.99995000000000000551\n",
      "[[4999    1    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   0    0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "#training with the max features set to 1,000,000 and testing on testand dev sets\n",
    "train_X = train['new']  \n",
    "train_y = train['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=1000000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=naive_bayes_classifier.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model to a pickle\n",
    "import pickle\n",
    "filename = 'model_train_tfidf.sav'\n",
    "pickle.dump(naive_bayes_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model_train = pickle.load(open(filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995309806307676\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long Europarl sample\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train.score(x_formal, formal_large.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9755861959455883\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short Europarl sample\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.99550569037589509147\n",
      "[[29249    86    10    10]\n",
      " [   16 32112     3    25]\n",
      " [  130   127 30389    34]\n",
      " [   27    78    12 31849]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long TED Talks sample\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=naive_bayes_classifier.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.98978169557928841193\n",
      "[[25020   231    29    66]\n",
      " [   61 27892    44    86]\n",
      " [  148   143 24217    59]\n",
      " [   54   144    20 27968]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short TED Talks sample\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=naive_bayes_classifier.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with data with all stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              de          en          es       fr\n",
      "precision: [0.99992499 0.99995    0.999975   0.999975  ]\n",
      "recall:    [0.99992499 0.999975   0.999975   0.99994999]\n",
      "f1 score:  [0.99992499 0.9999625  0.999975   0.9999625 ]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99997499 0.99967506 0.999975   0.999975  ]\n",
      "recall:    [0.99972497 0.999975   0.999975   0.99992499]\n",
      "f1 score:  [0.99984997 0.99982501 0.999975   0.99994999]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99994999 0.9999     1.         0.999975  ]\n",
      "recall:    [0.99989999 0.999975   0.999975   0.999975  ]\n",
      "f1 score:  [0.99992499 0.9999375  0.9999875  0.999975  ]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.999975 1.       0.999975 0.999975]\n",
      "recall:    [1.       0.999975 0.999975 0.999975]\n",
      "f1 score:  [0.9999875 0.9999875 0.999975  0.999975 ]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99997499 0.99982501 0.99995    1.        ]\n",
      "recall:    [0.99984998 1.         1.         0.99989999]\n",
      "f1 score:  [0.99991249 0.9999125  0.999975   0.99994999]\n",
      "--------------------------------------------------------\n",
      "accuracy: 99.995% (+/- 0.00%)\n",
      "precision: 99.995% (+/- 0.00%)\n",
      "recall: 99.995% (+/- 0.00%)\n",
      "f1 score: 99.995% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "#stratified k-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "X=train_sw.review_body\n",
    "Y=train_sw.language\n",
    "for train, test in kfold.split(X, Y):\n",
    "    lr_fit = bayes_pipeline_up_more.fit(X[train], Y[train])\n",
    "    prediction = lr_fit.predict(X[test])\n",
    "    scores = lr_fit.score(X[test],Y[test])\n",
    "    #model_result=lr_fit.predict(testing)\n",
    "    accuracy.append(scores * 100)\n",
    "    precision.append(precision_score(Y[test], prediction, average='macro')*100)\n",
    "    print('              de          en          es       fr')\n",
    "    print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "    recall.append(recall_score(Y[test], prediction, average='macro')*100)\n",
    "    print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "    f1.append(f1_score(Y[test], prediction, average='macro')*100)\n",
    "    print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "    print('-'*56)\n",
    "\n",
    "print(\"accuracy: %.3f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "print(\"precision: %.3f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "print(\"recall: %.3f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "print(\"f1 score: %.3f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.99990000000000001101\n",
      "[[5000    0    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   1    0    1 4998]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.99995000000000000551\n",
      "[[4999    1    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   0    0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "#training MNB over the data with all stop words preserved\n",
    "train_X = train_sw['review_body']   \n",
    "train_y = train_sw['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b', max_features=1000000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=naive_bayes_classifier.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model to a pickle\n",
    "import pickle\n",
    "filename1 = 'model__sw_train_tfidf.sav'\n",
    "pickle.dump(naive_bayes_classifier, open(filename1, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model_train_sw = pickle.load(open(filename1, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995309806307676\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long Europarl\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train_sw.score(x_formal, formal_large.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9755861959455883\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short Europarl\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train_sw.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.99550569037589509147\n",
      "[[29249    86    10    10]\n",
      " [   16 32112     3    25]\n",
      " [  130   127 30389    34]\n",
      " [   27    78    12 31849]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long TED Talks sample\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=naive_bayes_classifier.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.98927313480627598885\n",
      "[[25025   243    19    59]\n",
      " [   59 27934    29    61]\n",
      " [  180   171 24144    72]\n",
      " [   69   157    20 27940]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short TED Talks sample\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=naive_bayes_classifier.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
