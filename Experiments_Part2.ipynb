{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the packages\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spacy\n",
    "from collections import Counter\n",
    "#import en_core_web_sm\\\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spacy\n",
    "import langdetect\n",
    "from langdetect import detect\n",
    "import detectlanguage\n",
    "from google_trans_new import google_translator  \n",
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr_0112905</td>\n",
       "      <td>product_fr_0620743</td>\n",
       "      <td>reviewer_fr_0310864</td>\n",
       "      <td>1</td>\n",
       "      <td>Colis bien reçus avec le boîtier du jeu ouvert...</td>\n",
       "      <td>Commandé ailleurs si vous voulez des colis com...</td>\n",
       "      <td>fr</td>\n",
       "      <td>video_games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr_0345365</td>\n",
       "      <td>product_fr_0942745</td>\n",
       "      <td>reviewer_fr_0244013</td>\n",
       "      <td>1</td>\n",
       "      <td>Suite à une vérification, je vous informe que ...</td>\n",
       "      <td>COMMANDE NON RECUE</td>\n",
       "      <td>fr</td>\n",
       "      <td>office_product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr_0474170</td>\n",
       "      <td>product_fr_0183830</td>\n",
       "      <td>reviewer_fr_0816879</td>\n",
       "      <td>1</td>\n",
       "      <td>C'est un produit de piètre qualité sur quatre,...</td>\n",
       "      <td>Plastique sans aucune résistance !</td>\n",
       "      <td>fr</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr_0084156</td>\n",
       "      <td>product_fr_0195761</td>\n",
       "      <td>reviewer_fr_0933238</td>\n",
       "      <td>1</td>\n",
       "      <td>N'ont pas résistés. Piètre qualité</td>\n",
       "      <td>séparateur d'orteils</td>\n",
       "      <td>fr</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr_0893613</td>\n",
       "      <td>product_fr_0077995</td>\n",
       "      <td>reviewer_fr_0492122</td>\n",
       "      <td>1</td>\n",
       "      <td>Filament de qualité mais pas bien embobiné, ré...</td>\n",
       "      <td>ça coince, ça coince... que des problemes</td>\n",
       "      <td>fr</td>\n",
       "      <td>industrial_supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>en_0447642</td>\n",
       "      <td>product_en_0068982</td>\n",
       "      <td>reviewer_en_0061521</td>\n",
       "      <td>5</td>\n",
       "      <td>This ribbon is so adorable! Goes perfect with ...</td>\n",
       "      <td>So Cute!</td>\n",
       "      <td>en</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>en_0950370</td>\n",
       "      <td>product_en_0563046</td>\n",
       "      <td>reviewer_en_0871798</td>\n",
       "      <td>5</td>\n",
       "      <td>I am in love with this kettle.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>en</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>en_0203466</td>\n",
       "      <td>product_en_0848682</td>\n",
       "      <td>reviewer_en_0474236</td>\n",
       "      <td>5</td>\n",
       "      <td>My Doberman Loves Having His Nails Trimmed and...</td>\n",
       "      <td>My Doberman Loves Them</td>\n",
       "      <td>en</td>\n",
       "      <td>pet_products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>en_0010627</td>\n",
       "      <td>product_en_0536493</td>\n",
       "      <td>reviewer_en_0546192</td>\n",
       "      <td>5</td>\n",
       "      <td>I love my Fire.. I do everything on it, read, ...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>en</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>en_0290511</td>\n",
       "      <td>product_en_0964853</td>\n",
       "      <td>reviewer_en_0850986</td>\n",
       "      <td>5</td>\n",
       "      <td>A wish I would've ordered one size smaller (I ...</td>\n",
       "      <td>SUPER CUTE!</td>\n",
       "      <td>en</td>\n",
       "      <td>apparel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_id          product_id          reviewer_id  stars  \\\n",
       "0      fr_0112905  product_fr_0620743  reviewer_fr_0310864      1   \n",
       "1      fr_0345365  product_fr_0942745  reviewer_fr_0244013      1   \n",
       "2      fr_0474170  product_fr_0183830  reviewer_fr_0816879      1   \n",
       "3      fr_0084156  product_fr_0195761  reviewer_fr_0933238      1   \n",
       "4      fr_0893613  product_fr_0077995  reviewer_fr_0492122      1   \n",
       "...           ...                 ...                  ...    ...   \n",
       "19995  en_0447642  product_en_0068982  reviewer_en_0061521      5   \n",
       "19996  en_0950370  product_en_0563046  reviewer_en_0871798      5   \n",
       "19997  en_0203466  product_en_0848682  reviewer_en_0474236      5   \n",
       "19998  en_0010627  product_en_0536493  reviewer_en_0546192      5   \n",
       "19999  en_0290511  product_en_0964853  reviewer_en_0850986      5   \n",
       "\n",
       "                                             review_body  \\\n",
       "0      Colis bien reçus avec le boîtier du jeu ouvert...   \n",
       "1      Suite à une vérification, je vous informe que ...   \n",
       "2      C'est un produit de piètre qualité sur quatre,...   \n",
       "3                     N'ont pas résistés. Piètre qualité   \n",
       "4      Filament de qualité mais pas bien embobiné, ré...   \n",
       "...                                                  ...   \n",
       "19995  This ribbon is so adorable! Goes perfect with ...   \n",
       "19996                     I am in love with this kettle.   \n",
       "19997  My Doberman Loves Having His Nails Trimmed and...   \n",
       "19998  I love my Fire.. I do everything on it, read, ...   \n",
       "19999  A wish I would've ordered one size smaller (I ...   \n",
       "\n",
       "                                            review_title language  \\\n",
       "0      Commandé ailleurs si vous voulez des colis com...       fr   \n",
       "1                                     COMMANDE NON RECUE       fr   \n",
       "2                     Plastique sans aucune résistance !       fr   \n",
       "3                                   séparateur d'orteils       fr   \n",
       "4              ça coince, ça coince... que des problemes       fr   \n",
       "...                                                  ...      ...   \n",
       "19995                                           So Cute!       en   \n",
       "19996                                            Perfect       en   \n",
       "19997                             My Doberman Loves Them       en   \n",
       "19998                                         Five Stars       en   \n",
       "19999                                        SUPER CUTE!       en   \n",
       "\n",
       "          product_category  \n",
       "0              video_games  \n",
       "1           office_product  \n",
       "2               automotive  \n",
       "3                   sports  \n",
       "4      industrial_supplies  \n",
       "...                    ...  \n",
       "19995                 home  \n",
       "19996              kitchen  \n",
       "19997         pet_products  \n",
       "19998                other  \n",
       "19999              apparel  \n",
       "\n",
       "[20000 rows x 8 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading development datasets and concatenating thhem\n",
    "dev_de = pd.read_json(\"dataset_de_dev.json\", lines=True)\n",
    "dev_es = pd.read_json(\"dataset_es_dev.json\", lines=True)\n",
    "dev_en = pd.read_json(\"dataset_en_dev.json\", lines=True)\n",
    "dev_fr = pd.read_json(\"dataset_fr_dev.json\", lines=True)\n",
    "dev= pd.concat([dev_fr, dev_es, dev_de, dev_en], axis=0)\n",
    "dev.reset_index(drop=True, inplace=True)\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data pre-processed with unique linguistic characteristics\n",
    "train=pd.read_excel('train_df_clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set of Amazon Reviews Corpus\n",
    "test=pd.read_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Europarl test sample\n",
    "formal_large=pd.read_excel('formal_large.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>txt</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>vigueur engagements Kosovo,</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cela n'implique d'énormes</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>l'argent faveur pays</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>dépenses publiques, première</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>année plus importante</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                           txt lang\n",
       "0           0             0   vigueur engagements Kosovo,   fr\n",
       "1           1             1     cela n'implique d'énormes   fr\n",
       "2           2             2          l'argent faveur pays   fr\n",
       "3           3             3  dépenses publiques, première   fr\n",
       "4           4             4         année plus importante   fr"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Europarl truncated\n",
    "formal_short_nostop=pd.read_excel('formal_nostop.xlsx')\n",
    "formal_short_nostop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TED Talks short text sample\n",
    "functional=pd.read_excel('functional_words.xlsx')\n",
    "functional=functional[functional['text'].str.split().str.len().ge(2)]\n",
    "functional= functional[functional['text'].notnull()]\n",
    "\n",
    "functional.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I want you now to imagine a wearable robot tha...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We at Berkeley Bionics call these robots exosk...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text lang\n",
       "0           0  I want you now to imagine a wearable robot tha...   en\n",
       "1           1  We at Berkeley Bionics call these robots exosk...   en"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TED Talks long text sample\n",
    "ted_talk_full=pd.read_excel('tedtalk_full_large.xlsx')\n",
    "ted_talk_full=ted_talk_full[ted_talk_full['text'].str.split().str.len().ge(4)]\n",
    "ted_talk_full= ted_talk_full[ted_talk_full['text'].notnull()]\n",
    "ted_talk_full.reset_index(drop=True, inplace=True)\n",
    "ted_talk_full.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data with \n",
    "train_nostop=pd.read_excel('no_stopw.xlsx')\n",
    "#cleaning the data set\n",
    "train_nostop= train_nostop[train_nostop['review_body'].notnull()]\n",
    "train_nostop.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data with all stop words\n",
    "train_sw=pd.read_excel('train_sw.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traiing set with stemmed data\n",
    "train_lemma=pd.read_excel('train_lemma.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the performance of logistic Regression trained over the data the pre-processed accouting for linguistic nuances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature representation\n",
    "tvec_up_more = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=10000, ngram_range=(1, 3))\n",
    "lr = LogisticRegression()\n",
    "original_pipeline = Pipeline([\n",
    "    ('vectorizer', tvec_up_more),\n",
    "    ('classifier', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              de          en          es       fr\n",
      "precision: [0.99997498 0.99984998 0.99892597 0.99984992]\n",
      "recall:    [0.99944994 0.99979998 0.99992499 0.99942494]\n",
      "f1 score:  [0.9997124  0.99982498 0.99942523 0.99963739]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.9998999  0.99965003 0.99857681 0.99992494]\n",
      "recall:    [0.9990499  0.99982498 0.99994999 0.99922492]\n",
      "f1 score:  [0.99947472 0.9997375  0.99926293 0.99957481]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99994996 0.99982499 0.9988262  0.99994998]\n",
      "recall:    [0.99917492 0.99984998 0.99994999 0.99957496]\n",
      "f1 score:  [0.99956229 0.99983749 0.99938778 0.99976243]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99994997 0.99984998 0.99910067 0.99992496]\n",
      "recall:    [0.99944994 0.99984998 0.99994999 0.99957495]\n",
      "f1 score:  [0.99969989 0.99984998 0.99952515 0.99974992]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99994995 0.999725   0.99867652 0.99987492]\n",
      "recall:    [0.99912491 0.99982498 0.99992499 0.99934992]\n",
      "f1 score:  [0.99953726 0.99977499 0.99930037 0.99961235]\n",
      "--------------------------------------------------------\n",
      "accuracy: 99.961% (+/- 0.01%)\n",
      "precision: 99.961% (+/- 0.01%)\n",
      "recall: 99.961% (+/- 0.01%)\n",
      "f1 score: 99.961% (+/- 0.01%)\n"
     ]
    }
   ],
   "source": [
    "#stratified cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "X=train.new\n",
    "Y=train.language\n",
    "for train, test in kfold.split(X, Y):\n",
    "    lr_fit = original_pipeline.fit(X[train], Y[train])\n",
    "    prediction = lr_fit.predict(X[test])\n",
    "    scores = lr_fit.score(X[test],Y[test])\n",
    "    #model_result=lr_fit.predict(testing)\n",
    "    accuracy.append(scores * 100)\n",
    "    precision.append(precision_score(Y[test], prediction, average='macro')*100)\n",
    "    print('              de          en          es       fr')\n",
    "    print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "    recall.append(recall_score(Y[test], prediction, average='macro')*100)\n",
    "    print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "    f1.append(f1_score(Y[test], prediction, average='macro')*100)\n",
    "    print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "    print('-'*56)\n",
    "\n",
    "print(\"accuracy: %.3f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "print(\"precision: %.3f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "print(\"recall: %.3f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "print(\"f1 score: %.3f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.99955000000000004956\n",
      "[[4997    0    3    0]\n",
      " [   1 4999    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   1    0    4 4995]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.99965000000000003855\n",
      "[[4996    2    2    0]\n",
      " [   0 4999    1    0]\n",
      " [   0    0 5000    0]\n",
      " [   0    1    1 4998]]\n"
     ]
    }
   ],
   "source": [
    "#training the model and testing on test and dev sets\n",
    "train_X = train['new']   \n",
    "train_y = train['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=10000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_tf, train_y)\n",
    "y_pred = lr.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=lr.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving the model\n",
    "import pickle\n",
    "filename_lr = 'model_lr_10k.sav'\n",
    "pickle.dump(lr, open(filename_lr, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model_train_lr = pickle.load(open(filename_lr, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974647601663117\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long Europarl sample\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train_lr.score(x_formal, formal_large.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7897766368496268\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short Europarl sample\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train_lr.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.98866757411986438964\n",
      "[[29052    72   193    38]\n",
      " [   22 31950   122    62]\n",
      " [    6    69 30421   184]\n",
      " [   11    53   575 31327]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long TED Talks\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=lr.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.91823472905012148981\n",
      "[[22079   146  3020   101]\n",
      " [   90 25132  2119   742]\n",
      " [   10    41 24381   135]\n",
      " [   23   124  2131 25908]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short TED Talks\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=lr.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest 10,000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=10000, ngram_range=(1, 3))\n",
    "#a pipeline for Random Forest with 10,000\n",
    "rf = RandomForestClassifier()\n",
    "rf_pipeline = Pipeline([\n",
    "    ('vectorizer', tvec),\n",
    "    ('classifier', rf)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              de          en          es       fr\n",
      "precision: [0.99987491 0.99984989 0.99760515 0.99987486]\n",
      "recall:    [0.99922492 0.99924992 0.99984998 0.99887489]\n",
      "f1 score:  [0.99954981 0.99954982 0.99872631 0.99937462]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99987487 0.99984992 0.99720691 0.99972464]\n",
      "recall:    [0.9989749  0.99939994 0.99977498 0.99849985]\n",
      "f1 score:  [0.99942468 0.99962488 0.99848929 0.99911187]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99979979 0.99964992 0.99772926 0.99982482]\n",
      "recall:    [0.99884988 0.99952495 0.99969997 0.99892489]\n",
      "f1 score:  [0.99932461 0.99958743 0.99871364 0.99937466]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99987489 0.9996249  0.99780406 0.99974971]\n",
      "recall:    [0.99912491 0.99944994 0.99974997 0.99872484]\n",
      "f1 score:  [0.99949976 0.99953741 0.99877607 0.99923701]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99979976 0.99972486 0.99718169 0.9996246 ]\n",
      "recall:    [0.99869987 0.99929993 0.99964996 0.99867483]\n",
      "f1 score:  [0.99924951 0.99951235 0.9984143  0.99914949]\n",
      "--------------------------------------------------------\n",
      "accuracy: 99.921% (+/- 0.01%)\n",
      "precision: 99.921% (+/- 0.01%)\n",
      "recall: 99.921% (+/- 0.01%)\n",
      "f1 score: 99.921% (+/- 0.01%)\n"
     ]
    }
   ],
   "source": [
    "#stratified cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "X=train.new\n",
    "Y=train.language\n",
    "for train, test in kfold.split(X, Y):\n",
    "    lr_fit = rf_pipeline.fit(X[train], Y[train])\n",
    "    prediction = lr_fit.predict(X[test])\n",
    "    scores = lr_fit.score(X[test],Y[test])\n",
    "    #model_result=lr_fit.predict(testing)\n",
    "    accuracy.append(scores * 100)\n",
    "    precision.append(precision_score(Y[test], prediction, average='macro')*100)\n",
    "    print('              de          en          es       fr')\n",
    "    print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "    recall.append(recall_score(Y[test], prediction, average='macro')*100)\n",
    "    print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "    f1.append(f1_score(Y[test], prediction, average='macro')*100)\n",
    "    print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "    print('-'*56)\n",
    "\n",
    "print(\"accuracy: %.3f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "print(\"precision: %.3f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "print(\"recall: %.3f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "print(\"f1 score: %.3f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.99909999999999998810\n",
      "[[4996    0    4    0]\n",
      " [   2 4996    2    0]\n",
      " [   0    1 4998    1]\n",
      " [   0    1    7 4992]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.99919999999999997708\n",
      "[[4995    1    4    0]\n",
      " [   1 4998    1    0]\n",
      " [   0    0 4998    2]\n",
      " [   0    4    3 4993]]\n"
     ]
    }
   ],
   "source": [
    "#training the model and testing on test and dev sets\n",
    "train_X = train['new']   \n",
    "train_y = train['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=10000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_tf, train_y)\n",
    "y_pred = rf.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=rf.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "import pickle\n",
    "filename_rf = 'model_train_rf.sav'\n",
    "pickle.dump(rf, open(filename_rf, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model_train_rf = pickle.load(open(filename_rf, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9962731974444783\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long Europarl sample\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train_rf.score(x_formal, formal_large.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6967263007463081\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short Europarl sample\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train_rf.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.98113678648807556293\n",
      "[[28825    64   400    66]\n",
      " [   28 31722   320    86]\n",
      " [   19    71 30326   264]\n",
      " [   15    74   935 30942]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long TED Talks sample\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=rf.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.85109528922039512366\n",
      "[[19986   109  5151   100]\n",
      " [  128 21847  5427   681]\n",
      " [   18    24 24379   146]\n",
      " [   35   159  3833 24159]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short TED Talks sample\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=rf.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline one-vs-rest svm \n",
    "svc = OneVsRestClassifier(SVC())\n",
    "svc_pipeline = Pipeline([\n",
    "    ('vectorizer', tvec),\n",
    "    ('classifier', svc)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              de          en          es       fr\n",
      "precision: [0.99992499 0.99995    0.999975   0.999975  ]\n",
      "recall:    [0.99992499 0.999975   0.999975   0.99994999]\n",
      "f1 score:  [0.99992499 0.9999625  0.999975   0.9999625 ]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99997499 0.99967506 0.999975   0.999975  ]\n",
      "recall:    [0.99972497 0.999975   0.999975   0.99992499]\n",
      "f1 score:  [0.99984997 0.99982501 0.999975   0.99994999]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99994999 0.9999     1.         0.999975  ]\n",
      "recall:    [0.99989999 0.999975   0.999975   0.999975  ]\n",
      "f1 score:  [0.99992499 0.9999375  0.9999875  0.999975  ]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.999975 1.       0.999975 0.999975]\n",
      "recall:    [1.       0.999975 0.999975 0.999975]\n",
      "f1 score:  [0.9999875 0.9999875 0.999975  0.999975 ]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99997499 0.99982501 0.99995    1.        ]\n",
      "recall:    [0.99984998 1.         1.         0.99989999]\n",
      "f1 score:  [0.99991249 0.9999125  0.999975   0.99994999]\n",
      "--------------------------------------------------------\n",
      "accuracy: 99.995% (+/- 0.00%)\n",
      "precision: 99.995% (+/- 0.00%)\n",
      "recall: 99.995% (+/- 0.00%)\n",
      "f1 score: 99.995% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "#stratified cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "X=train.new\n",
    "Y=train.language\n",
    "for train, test in kfold.split(X, Y):\n",
    "    lr_fit = svc_pipeline.fit(X[train], Y[train])\n",
    "    prediction = lr_fit.predict(X[test])\n",
    "    scores = lr_fit.score(X[test],Y[test])\n",
    "    #model_result=lr_fit.predict(testing)\n",
    "    accuracy.append(scores * 100)\n",
    "    precision.append(precision_score(Y[test], prediction, average='macro')*100)\n",
    "    print('              de          en          es       fr')\n",
    "    print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "    recall.append(recall_score(Y[test], prediction, average='macro')*100)\n",
    "    print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "    f1.append(f1_score(Y[test], prediction, average='macro')*100)\n",
    "    print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "    print('-'*56)\n",
    "\n",
    "print(\"accuracy: %.3f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "print(\"precision: %.3f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "print(\"recall: %.3f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "print(\"f1 score: %.3f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.99955000000000004956\n",
      "[[4999    0    1    0]\n",
      " [   1 4999    0    0]\n",
      " [   1    0 4999    0]\n",
      " [   5    0    1 4994]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.99965000000000003855\n",
      "[[4997    3    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   1    0 4999    0]\n",
      " [   1    2    0 4997]]\n"
     ]
    }
   ],
   "source": [
    "#training the model and testing on test and dev data sets\n",
    "train_X = train['new']  \n",
    "train_y = train['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=10000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "svc = OneVsRestClassifier(SVC())\n",
    "svc.fit(X_train_tf, train_y)\n",
    "y_pred = svc.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=svc.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading into pickle\n",
    "import pickle\n",
    "filename1 = 'model__svc.sav'\n",
    "pickle.dump(svc, open(filename1, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model_train_svc = pickle.load(open(filename1, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9966661596187\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long Europarl sample\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train_svc.score(x_formal, formal_large.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7933890859048325\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short Europarl sample\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train_svc.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.97573233889349775261\n",
      "[[29240    59    25    31]\n",
      " [   89 31982    44    41]\n",
      " [ 1887    75 28598   120]\n",
      " [  478    72    92 31324]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long TED Talks sample\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=svc.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.91359175754836041694\n",
      "[[24771   274   182   119]\n",
      " [ 1197 26097   410   379]\n",
      " [ 4187    73 20205   102]\n",
      " [ 1764   164   324 25934]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short TED Talks sample\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=svc.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of MNB with data pre-processed with stop words removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              de          en          es       fr\n",
      "precision: [0.99994996 0.99957505 0.99935029 0.99982495]\n",
      "recall:    [0.99932488 0.99979998 0.99992499 0.99964996]\n",
      "f1 score:  [0.99963732 0.9996875  0.99963756 0.99973745]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99984991 0.99950007 0.99940018 0.99977492]\n",
      "recall:    [0.99939989 0.99974997 0.99982498 0.99954994]\n",
      "f1 score:  [0.99962485 0.99962501 0.99961253 0.99966242]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99979987 0.99945003 0.99974997 0.99925015]\n",
      "recall:    [0.99932488 0.99962495 0.99972497 0.99957495]\n",
      "f1 score:  [0.99956232 0.99953748 0.99973747 0.99941252]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99984994 0.99930024 0.99982496 0.99982495]\n",
      "recall:    [0.99964993 0.99977497 0.99972497 0.99964996]\n",
      "f1 score:  [0.99974992 0.99953755 0.99977497 0.99973745]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.9997749  0.99940019 0.99974999 0.99982493]\n",
      "recall:    [0.99954991 0.99984998 0.99982498 0.99952495]\n",
      "f1 score:  [0.99966239 0.99962504 0.99978749 0.99967492]\n",
      "--------------------------------------------------------\n",
      "accuracy: 99.965% (+/- 0.01%)\n",
      "precision: 99.965% (+/- 0.01%)\n",
      "recall: 99.965% (+/- 0.01%)\n",
      "f1 score: 99.965% (+/- 0.01%)\n"
     ]
    }
   ],
   "source": [
    "#stratified cross-validation \n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "X=train_nostop.review_body\n",
    "Y=train_nostop.language\n",
    "for train, test in kfold.split(X, Y):\n",
    "    lr_fit = bayes_pipeline_up_more.fit(X[train], Y[train])\n",
    "    prediction = lr_fit.predict(X[test])\n",
    "    scores = lr_fit.score(X[test],Y[test])\n",
    "    #model_result=lr_fit.predict(testing)\n",
    "    accuracy.append(scores * 100)\n",
    "    precision.append(precision_score(Y[test], prediction, average='macro')*100)\n",
    "    print('              de          en          es       fr')\n",
    "    print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "    recall.append(recall_score(Y[test], prediction, average='macro')*100)\n",
    "    print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "    f1.append(f1_score(Y[test], prediction, average='macro')*100)\n",
    "    print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "    print('-'*56)\n",
    "\n",
    "print(\"accuracy: %.3f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "print(\"precision: %.3f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "print(\"recall: %.3f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "print(\"f1 score: %.3f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.97980000000000000426\n",
      "[[4994    3    1    2]\n",
      " [ 247 4743    1    9]\n",
      " [  91    2 4902    5]\n",
      " [  26   12    5 4957]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.98219999999999996199\n",
      "[[4994    4    1    1]\n",
      " [ 221 4765    0   14]\n",
      " [  80    1 4913    6]\n",
      " [  11    9    8 4972]]\n"
     ]
    }
   ],
   "source": [
    "#training the model on data with no stop words. Testing the model\n",
    "train_X = train_nostop['review_body']   \n",
    "train_y = train_nostop['language']  \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b', max_features=1000000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=naive_bayes_classifier.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "import pickle\n",
    "filename2 = 'model_nostop_train_tfidf.sav'\n",
    "pickle.dump(naive_bayes_classifier, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model_train_nostop = pickle.load(open(filename2, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151936923232938\n"
     ]
    }
   ],
   "source": [
    "#testing the model on long Europarl sample\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train_nostop.score(x_formal, formal_large.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9117662626369555\n"
     ]
    }
   ],
   "source": [
    "#testing the model on short Europarl\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train_nostop.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.72981789186272216785\n",
      "[[24852  1893  1513  1097]\n",
      " [ 9520 19078   814  2744]\n",
      " [ 7655   914 21346   765]\n",
      " [ 3931  1081  1618 25336]]\n"
     ]
    }
   ],
   "source": [
    "#testing the model on long TED Talks sample\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=naive_bayes_classifier.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.89526473413572926763\n",
      "[[22366  1280  1209   491]\n",
      " [ 2695 23993   610   785]\n",
      " [  137   371 23654   405]\n",
      " [  578   931  1629 25048]]\n"
     ]
    }
   ],
   "source": [
    "#testing the model on short TED Talks sample\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=naive_bayes_classifier.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNB trained over the stemmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              de          en          es       fr\n",
      "precision: [0.99987499 0.99989999 0.99989998 0.99984999]\n",
      "recall:    [0.99989999 0.99992499 0.99982498 0.99987499]\n",
      "f1 score:  [0.99988749 0.99991249 0.99986248 0.99986249]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99970001 0.99987498 0.999775   0.99984995]\n",
      "recall:    [0.99982498 0.99984998 0.99987499 0.99964996]\n",
      "f1 score:  [0.99976249 0.99986248 0.99982499 0.99974995]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99965007 0.99992499 0.9998     0.99992497]\n",
      "recall:    [0.99994999 0.99984998 0.99989999 0.99959996]\n",
      "f1 score:  [0.99980001 0.99988748 0.99984999 0.99976244]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.999825   0.99994999 0.99989999 0.99984997]\n",
      "recall:    [0.99994999 0.99989999 0.99987499 0.99979997]\n",
      "f1 score:  [0.9998875  0.99992499 0.99988749 0.99982497]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99989999 0.99989999 0.99975001 0.99989997]\n",
      "recall:    [0.99992499 0.99989999 0.99989999 0.99972497]\n",
      "f1 score:  [0.99991249 0.99989999 0.999825   0.99981246]\n",
      "--------------------------------------------------------\n",
      "accuracy: 99.985% (+/- 0.00%)\n",
      "precision: 99.985% (+/- 0.00%)\n",
      "recall: 99.985% (+/- 0.00%)\n",
      "f1 score: 99.985% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "#stratified cross-validation  \n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "X=train_lemma.review_body\n",
    "Y=train_lemma.language\n",
    "for train, test in kfold.split(X, Y):\n",
    "    lr_fit = bayes_pipeline_up_more.fit(X[train], Y[train])\n",
    "    prediction = lr_fit.predict(X[test])\n",
    "    scores = lr_fit.score(X[test],Y[test])\n",
    "    #model_result=lr_fit.predict(testing)\n",
    "    accuracy.append(scores * 100)\n",
    "    precision.append(precision_score(Y[test], prediction, average='macro')*100)\n",
    "    print('              de          en          es       fr')\n",
    "    print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "    recall.append(recall_score(Y[test], prediction, average='macro')*100)\n",
    "    print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "    f1.append(f1_score(Y[test], prediction, average='macro')*100)\n",
    "    print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "    print('-'*56)\n",
    "\n",
    "print(\"accuracy: %.3f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "print(\"precision: %.3f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "print(\"recall: %.3f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "print(\"f1 score: %.3f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.99555000000000004601\n",
      "[[4989    8    2    1]\n",
      " [   6 4989    1    4]\n",
      " [   7    8 4977    8]\n",
      " [  14    5   25 4956]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.99550000000000005151\n",
      "[[4984   11    4    1]\n",
      " [   3 4993    2    2]\n",
      " [  11    5 4976    8]\n",
      " [  14    4   25 4957]]\n"
     ]
    }
   ],
   "source": [
    "#training the model over the stemmed data and testing it on test and dev sets.\n",
    "train_X = train_lemma['review_body'] \n",
    "train_y = train_lemma['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b', max_features=1000000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=naive_bayes_classifier.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "import pickle\n",
    "filename7 = 'model_lemma_train_tfidf.sav'\n",
    "pickle.dump(naive_bayes_classifier, open(filename7, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956267112868877\n",
      "0.920125\n",
      "0.6798285079129837\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_model_train_lemma = pickle.load(open(filename7, 'rb'))\n",
    "#testing on long Europarl sample\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train_lemma.score(x_formal, formal_large.lang)\n",
    "print(result)\n",
    "\n",
    "#testing on short Europarl sample\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train_lemma.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.97109305153958291879\n",
      "[[28978   283    55    39]\n",
      " [   49 32064    15    28]\n",
      " [  242   287 29244   907]\n",
      " [  244   118  1322 30282]]\n"
     ]
    }
   ],
   "source": [
    "#testing on long TED Talks sample\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=naive_bayes_classifier.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.78453033470833100083\n",
      "[[23996   878   226   246]\n",
      " [ 1310 25982   345   446]\n",
      " [12788  1378  9737   664]\n",
      " [ 3394   852   352 23588]]\n"
     ]
    }
   ],
   "source": [
    "#testing on short TED Talks sample\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=naive_bayes_classifier.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model's performance with no punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata \n",
    "import sys\n",
    "#removing punctuation\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                           if unicodedata.category(chr(i)).startswith('P'))\n",
    "train['new'] = train['new'].apply(lambda item: ' '.join([string.translate(punctuation) for string in item.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.99995000000000000551\n",
      "[[5000    0    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   1    0    0 4999]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.99995000000000000551\n",
      "[[4999    1    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   0    0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "#training MNB over the data with no punctuation\n",
    "train_X = train['new']   \n",
    "train_y = train['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b', max_features=1000000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = tf_vectorizer.fit_transform(train_X)\n",
    "X_test_tf = tf_vectorizer.transform(test_X)\n",
    "x_dev=tf_vectorizer.transform(dev.review_body)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=naive_bayes_classifier.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "import pickle\n",
    "filename_punct = 'model_train_punct_removed.sav'\n",
    "pickle.dump(naive_bayes_classifier, open(filename_punct, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_punct_train = pickle.load(open(filename_punct, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995056282324308\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long Europarl sample\n",
    "x_formal=tf_vectorizer.transform(formal_large.txt)\n",
    "result = loaded_punct_train.score(x_formal, formal_large.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9758640766421426\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short Europarl sample\n",
    "x_formal_short_nostop=tf_vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_punct_train.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.99551374469421782809\n",
      "[[29248    87    10    10]\n",
      " [   16 32111     3    26]\n",
      " [  127   127 30390    36]\n",
      " [   27    76    12 31851]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy on long TED Talks sample\n",
    "x_tedtalk=tf_vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=naive_bayes_classifier.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.98978169557928841193\n",
      "[[25023   231    28    64]\n",
      " [   59 27892    44    88]\n",
      " [  152   140 24214    61]\n",
      " [   54   145    19 27968]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy on short TED talks sample\n",
    "x_long_words=tf_vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=naive_bayes_classifier.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Use of CountVectorizer instead of TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              de          en          es       fr\n",
      "precision: [0.99995  0.999975 1.       0.999975]\n",
      "recall:    [0.999975   0.999975   1.         0.99994999]\n",
      "f1 score:  [0.9999625 0.999975  1.        0.9999625]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99987498 0.99980001 1.         0.999975  ]\n",
      "recall:    [0.99984998 0.999975   0.99992499 0.99989999]\n",
      "f1 score:  [0.99986248 0.9998875  0.99996249 0.99993749]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.999975 0.999925 1.       0.999975]\n",
      "recall:    [0.99992499 0.999975   0.999975   1.        ]\n",
      "f1 score:  [0.99994999 0.99995    0.9999875  0.9999875 ]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.999975 0.999975 0.999975 0.999975]\n",
      "recall:    [0.999975   0.99994999 1.         0.999975  ]\n",
      "f1 score:  [0.999975  0.9999625 0.9999875 0.999975 ]\n",
      "--------------------------------------------------------\n",
      "              de          en          es       fr\n",
      "precision: [0.99989999 0.99985    1.         1.        ]\n",
      "recall:    [0.99987499 0.999975   0.999975   0.99992499]\n",
      "f1 score:  [0.99988749 0.9999125  0.9999875  0.99996249]\n",
      "--------------------------------------------------------\n",
      "accuracy: 99.995% (+/- 0.00%)\n",
      "precision: 99.995% (+/- 0.00%)\n",
      "recall: 99.995% (+/- 0.00%)\n",
      "f1 score: 99.995% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "#stratified cross-validation\n",
    "vectorizer = CountVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=1000000, ngram_range=(1, 3)) # or term frequency\n",
    "clf = MultinomialNB()\n",
    "bayes_pipeline_vec = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "#creating the function to print out the results of the modeling and pre   \n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "X=train.new\n",
    "Y=train.language\n",
    "for train, test in kfold.split(X, Y):\n",
    "    lr_fit = bayes_pipeline_vec.fit(X[train], Y[train])\n",
    "    prediction = lr_fit.predict(X[test])\n",
    "    scores = lr_fit.score(X[test],Y[test])\n",
    "    #model_result=lr_fit.predict(testing)\n",
    "    accuracy.append(scores * 100)\n",
    "    precision.append(precision_score(Y[test], prediction, average='macro')*100)\n",
    "    print('              de          en          es       fr')\n",
    "    print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "    recall.append(recall_score(Y[test], prediction, average='macro')*100)\n",
    "    print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "    f1.append(f1_score(Y[test], prediction, average='macro')*100)\n",
    "    print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "    print('-'*56)\n",
    "\n",
    "print(\"accuracy: %.3f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "print(\"precision: %.3f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "print(\"recall: %.3f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "print(\"f1 score: %.3f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))\n",
    "#return(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set:   0.99995000000000000551\n",
      "[[5000    0    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   1    0    0 4999]]\n",
      "------------------------------\n",
      "accuracy validation set:  0.99995000000000000551\n",
      "[[4999    1    0    0]\n",
      " [   0 5000    0    0]\n",
      " [   0    0 5000    0]\n",
      " [   0    0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "#training MNB using CountVectorizer instead of TF-IDF\n",
    "train_X = train['new']   \n",
    "train_y = train['language']   \n",
    "test_X = test['review_body']\n",
    "test_y = test['language']\n",
    "vectorizer = CountVectorizer(stop_words=None,token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b|„|¿|¡', max_features=1000000, ngram_range=(1, 3)) # or term frequency\n",
    "X_train_tf = vectorizer.fit_transform(train_X)\n",
    "X_test_tf = vectorizer.transform(test_X)\n",
    "x_dev=vectorizer.transform(dev.review_body)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "score1 = metrics.accuracy_score(test_y, y_pred)\n",
    "print(\"accuracy test set:   %0.20f\" % score1)\n",
    "print(metrics.confusion_matrix(test_y, y_pred))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_2=naive_bayes_classifier.predict(x_dev)\n",
    "score2 = metrics.accuracy_score(dev.language, y_pred_2)\n",
    "print(\"accuracy validation set:  %0.20f\" % score2)\n",
    "print(metrics.confusion_matrix(dev.language, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "import pickle\n",
    "filename13 = 'model_count_train_count.sav'\n",
    "pickle.dump(naive_bayes_classifier, open(filename13, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model_train_count = pickle.load(open(filename13, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995563330291045\n"
     ]
    }
   ],
   "source": [
    "#accuracu for log Europarl sample\n",
    "x_formal=vectorizer.transform(formal_large.txt)\n",
    "result = loaded_model_train_count.score(x_formal, formal_large.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775313608214683\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short EUroparl sample\n",
    "x_formal_short_nostop=vectorizer.transform(formal_short_nostop.txt)\n",
    "result = loaded_model_train_count.score(x_formal_short_nostop, formal_short_nostop.lang)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.99618225311500763208\n",
      "[[29284    56     6     9]\n",
      " [   11 32128     3    14]\n",
      " [  131   112 30402    35]\n",
      " [   26    59    12 31869]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for long TED Talks sample\n",
    "x_tedtalk=vectorizer.transform(ted_talk_full.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_5=naive_bayes_classifier.predict(x_tedtalk)\n",
    "score5 = metrics.accuracy_score(ted_talk_full.lang, y_pred_5)\n",
    "print(\"accuracy validation set:  %0.20f\" % score5)\n",
    "print(metrics.confusion_matrix(ted_talk_full.lang, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy validation set:  0.99085532387787011999\n",
      "[[25056   207    27    56]\n",
      " [   64 27921    27    71]\n",
      " [  147   126 24249    45]\n",
      " [   53   124    24 27985]]\n"
     ]
    }
   ],
   "source": [
    "#accuracy for short TED Talks sample\n",
    "x_long_words=vectorizer.transform(functional.text)\n",
    "print('------------------------------')\n",
    "\n",
    "y_pred_7=naive_bayes_classifier.predict(x_long_words)\n",
    "score7 = metrics.accuracy_score(functional.lang, y_pred_7)\n",
    "print(\"accuracy validation set:  %0.20f\" % score7)\n",
    "print(metrics.confusion_matrix(functional.lang, y_pred_7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
